{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用python实现kNN近邻算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.处理数据\n",
    "首先我们需要读取数据。csv格式是没有任何标题，我们可以使用open函数来打开文件，使用csv模块对数据进行读写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('E:/Kaggle/iris.data', 'rb') as csvfile:\n",
    "    lines = csv.reader(csvfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们需要将数据划分为训练集和测试集。首先我们先要将字符串转换成为数字，然后我们需要将数据集随机划分成为训练集和测试集，我们采用训练集和测试的比例是66/34。\n",
    "\n",
    "之后我们将定义一个函数loadDataset，这个函数的作用是加载csv数据，按照66/34的比例随机划分训练集和测试集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "def load_dataset(filename, split, trainset=[], testset=[]):\n",
    "    with open(filename) as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        for x in range(len(dataset)-1):\n",
    "            for y in range(4):\n",
    "                dataset[x][y] = float(dataset[x][y])\n",
    "            if random.random() < split:\n",
    "                trainset.append(dataset[x])\n",
    "            else:\n",
    "                testset.append(dataset[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载iris数据到本地路径，我们可以使用iris数据测试一下loadDataset函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:105\n",
      "Test:44\n"
     ]
    }
   ],
   "source": [
    "trainset = []\n",
    "testset = []\n",
    "load_dataset('E:/Kaggle/iris.data', 0.66, trainset, testset)\n",
    "print ('Train:' + repr(len(trainset)))\n",
    "print ('Test:' + repr(len(testset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.相似度\n",
    "为了预测我们必须计算任意两个数据实例之间的相似性。这可以让我们在训练集中给定测试数据找到与k个最相似的数据实例。\n",
    "\n",
    "鉴于所有测量花的数据都是具有相同的单位(所以这里不用进行归一化处理)，我们可以直接使用欧氏距离度量。这里定义欧氏距离为连个数组之间的平方差之和的平方根。\n",
    "\n",
    "此外，我们想要控制哪些特征包含在距离计算。具体来说，我们只想包含前四个属性。一种方式是将欧氏距离限制为固定长度，忽略最终的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(instance1, instance2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += pow(instance1[x] - instance2[x], 2)\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用一些样例数据来测试euclideanDistance函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance:3.4641016151377544\n"
     ]
    }
   ],
   "source": [
    "data1 = [2, 2, 2, 'a']\n",
    "data2 = [4, 4, 4, 'b']\n",
    "distance = euclidean_distance(data1, data2, 3)\n",
    "print ('Distance:' + repr(distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.近邻\n",
    "现在我们有相似度的度量，我们可以在给定一个未知的数据集，用来汇集k个最相似的实例。\n",
    "\n",
    "这是一个直接的过程，计算所有实例的距离，并选择含有最小距离值的子集。\n",
    "\n",
    "下面的getNeighbours函数是根据一个给定的测试实例，返回的k个最相似的近邻集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def get_neighbours(trainset, test_instance, k):\n",
    "    distances = []\n",
    "    length = len(test_instance) - 1\n",
    "    for x in range(len(trainset)):\n",
    "        dist = euclidean_distance(test_instance, trainset[x], length)\n",
    "        distances.append((trainset[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbours = []\n",
    "    for x in range(k):\n",
    "        neighbours.append(distances[x][0])\n",
    "    return neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以测试getNeighbours函数，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 4, 4, 'b']]\n"
     ]
    }
   ],
   "source": [
    "trainset = [[2, 2, 2, 'a'], [4, 4, 4, 'b']]\n",
    "test_instance = [5, 5, 5]\n",
    "k = 1\n",
    "neighbours = get_neighbours(trainset, test_instance, 1)\n",
    "print ((neighbours))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.回应\n",
    "一旦我们找到了和测试实例最相似的近邻集，下一步根据这些近邻集设计一个回应。\n",
    "\n",
    "我们可以做到这一点，允许每个近邻投票他们的类的属性，并采取获得多数票作为预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def get_response(neighbours):\n",
    "    classvotes = {}\n",
    "    for x in range(len(neighbours)):\n",
    "        response = neighbours[x][-1]\n",
    "        if response in classvotes:\n",
    "            classvotes[response] += 1\n",
    "        else:\n",
    "            classvotes[response] = 1\n",
    "        sortedvotes = sorted(classvotes.items() ,key=operator.itemgetter(1), reverse=True)\n",
    "        return sortedvotes[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用测试数据来测试getResponse函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "neighbours = [[1, 1, 1, 'a'], [2, 2, 2, 'a'], [3, 3, 3, 'b']]\n",
    "response = get_response(neighbours)\n",
    "print ((response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.准确率\n",
    "我们已经实现了kNN算法的各个部分，剩下的一个重要的问题就是如何评估预测的准确性。\n",
    "\n",
    "一个简单的方法来评估该模型的准确性是计算正确的预测占所有预测的比率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(testset, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testset)):\n",
    "        if testset[x][-1] is predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testset))) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以通过一个测试数据和预测数据来测试getAccuracy函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "testset = [[1, 1, 1, 'a'], [2, 2, 2, 'a'], [3, 3, 3, 'b']]\n",
    "predictions = ['a', 'a', 'a']\n",
    "accuracy = get_accuracy(testset, predictions)\n",
    "print ((accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "kNN算法完整的代码如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainSet:96\n",
      "TestSet:53\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-setosa', actual='Iris-setosa'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-virginica', actual='Iris-versicolor'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-versicolor', actual='Iris-versicolor'\n",
      "predicted='Iris-virginica', actual='Iris-virginica'\n",
      "predicted='Iris-virginica', actual='Iris-virginica'\n",
      "predicted='Iris-versicolor', actual='Iris-virginica'\n",
      "predicted='Iris-virginica', actual='Iris-virginica'\n",
      "predicted='Iris-virginica', actual='Iris-virginica'\n",
      "predicted='Iris-virginica', actual='Iris-virginica'\n",
      "predicted='Iris-virginica', actual='Iris-virginica'\n",
      "predicted='Iris-virginica', actual='Iris-virginica'\n",
      "predicted='Iris-virginica', actual='Iris-virginica'\n",
      "predicted='Iris-virginica', actual='Iris-virginica'\n",
      "predicted='Iris-virginica', actual='Iris-virginica'\n",
      "predicted='Iris-virginica', actual='Iris-virginica'\n",
      "predicted='Iris-virginica', actual='Iris-virginica'\n",
      "==================================\n",
      "Accuracy:96.22641509433963%\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "\n",
    "def load_dataset(filename, split, trainset=[], testset=[]):\n",
    "    with open(filename) as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        for x in range(len(dataset)-1):\n",
    "            for y in range(4):\n",
    "                dataset[x][y] = float(dataset[x][y])\n",
    "            if random.random() < split:\n",
    "                trainset.append(dataset[x])\n",
    "            else:\n",
    "                testset.append(dataset[x])\n",
    "\n",
    "def euclidean_distance(instance1, instance2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += (instance1[x] - instance2[x]) ** 2\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "def get_neighbours(trainset, test_instance, k):\n",
    "    distances = []\n",
    "    length = len(test_instance) - 1\n",
    "    for x in range(len(trainset)):\n",
    "        dist = euclidean_distance(test_instance, trainset[x], length)\n",
    "        distances.append((trainset[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbours = []\n",
    "    for x in range(k):\n",
    "        neighbours.append(distances[x][0])\n",
    "    return neighbours\n",
    "\n",
    "def get_response(neighbours):\n",
    "    classvotes = {}\n",
    "    for x in range(len(neighbours)):\n",
    "        response = neighbours[x][-1]\n",
    "        if response in classvotes:\n",
    "            classvotes[response] += 1\n",
    "        else:\n",
    "            classvotes[response] = 1\n",
    "        sortedvotes = sorted(classvotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        return sortedvotes[0][0]\n",
    "\n",
    "def get_accuracy(testset, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testset)):\n",
    "        if testset[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct / float(len(testset))) * 100\n",
    "\n",
    "def main():\n",
    "    # 读取数据\n",
    "    trainset = []\n",
    "    testset = []\n",
    "    split = 0.66\n",
    "    load_dataset('E:/Kaggle/iris.data', 0.66, trainset, testset)\n",
    "    print ('TrainSet:' + repr(len(trainset)))\n",
    "    print ('TestSet:' + repr(len(testset)))\n",
    "\n",
    "    # 作出预测\n",
    "    predictions = []\n",
    "    k = 3\n",
    "    for x in range(len(testset)):\n",
    "        neighbours = get_neighbours(trainset, testset[x], k)\n",
    "        result = get_response(neighbours)\n",
    "        predictions.append(result)\n",
    "        print (('predicted=' + repr(result) + ', actual=' + repr(testset[x][-1])))\n",
    "    accuracy = get_accuracy(testset, predictions)\n",
    "    print ('==================================')\n",
    "    print (('Accuracy:' + repr(accuracy) + '%'))\n",
    "    print ('==================================')\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
