{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Python实现Decision Tree算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、基尼系数\n",
    "\n",
    "基尼系数是用于评估数据集中分割的成本函数的名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gini_index(groups, class_values):\n",
    "    gini = 0.0\n",
    "    for class_value in class_values:\n",
    "        for group in groups:\n",
    "            size = len(group)\n",
    "            if size == 0:\n",
    "                continue\n",
    "            proportion = [row[-1] for row in group].count(class_value) / float(size)\n",
    "            gini += (proportion * (1.0 - proportion))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以设计一个小数据集来测试我们的gini_index()函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print ((gini_index([[[1, 1], [1, 0]], [[1, 1], [1, 0]]], [0, 1])))\n",
    "print ((gini_index([[[1, 0], [1, 0]], [[1, 1], [1, 1]]], [0, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、创建划分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1、划分一个数据集\n",
    "\n",
    "拆分数据集意味着在给定属性的索引和该属性的拆分值的情况下将数据集分为两组。\n",
    "\n",
    "一旦我们有两组，我们可以使用我们的Gini得分来评估划分的情况。\n",
    "\n",
    "划分数据集包括对每行进行迭代，检查属性值是低于还是高于划分值，并分别将其分配给左侧组或右侧组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_split(index, value, dataset):\n",
    "    left, right = [], []\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2、评估全部划分\n",
    "\n",
    "使用上面的Gini函数和测试划分函数，我们现在来评估拆分。\n",
    "\n",
    "给定一个数据集，我们必须检查每个属性上的每个值作为候选划分，评估划分的效果，并找到我们可能做出的最佳划分。\n",
    "\n",
    "当最好的划分确定之后，我们可以用来作为决策树的节点。\n",
    "\n",
    "我们将使用字典来表示决策树中的一个节点，因为我们可以按名称存储数据。 当选择最佳划分并将其用作树的新节点时，我们将存储所选属性的索引，要划分的属性的值以及由所选划分点划分的两组数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            print('X%d < %.3f Gini=%.3f' % ((index+1), row[index], gini))\n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以设计一个小数据集来测试我们的get_split()函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 < 2.771 Gini=0.494\n",
      "X1 < 1.729 Gini=0.500\n",
      "X1 < 3.678 Gini=0.408\n",
      "X1 < 3.961 Gini=0.278\n",
      "X1 < 2.999 Gini=0.469\n",
      "X1 < 7.498 Gini=0.408\n",
      "X1 < 9.002 Gini=0.469\n",
      "X1 < 7.445 Gini=0.278\n",
      "X1 < 10.125 Gini=0.494\n",
      "X1 < 6.642 Gini=0.000\n",
      "X2 < 1.785 Gini=1.000\n",
      "X2 < 1.170 Gini=0.494\n",
      "X2 < 2.813 Gini=0.640\n",
      "X2 < 2.620 Gini=0.819\n",
      "X2 < 2.209 Gini=0.934\n",
      "X2 < 3.163 Gini=0.278\n",
      "X2 < 3.339 Gini=0.494\n",
      "X2 < 0.477 Gini=0.500\n",
      "X2 < 3.235 Gini=0.408\n",
      "X2 < 3.320 Gini=0.469\n",
      "Split: [X1 < 6.642]\n"
     ]
    }
   ],
   "source": [
    "dataset = [[2.771244718,1.784783929,0],\n",
    "    [1.728571309,1.169761413,0],\n",
    "    [3.678319846,2.81281357,0],\n",
    "    [3.961043357,2.61995032,0],\n",
    "    [2.999208922,2.209014212,0],\n",
    "    [7.497545867,3.162953546,1],\n",
    "    [9.00220326,3.339047188,1],\n",
    "    [7.444542326,0.476683375,1],\n",
    "    [10.12493903,3.234550982,1],\n",
    "    [6.642287351,3.319983761,1]]\n",
    "split = get_split(dataset)\n",
    "print (('Split: [X%d < %.3f]' % ((split['index']+1), split['value'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3、建立一颗决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.1、终止节点\n",
    "\n",
    "我们需要决定什么时候停止树的成长。我们可以使用节点在训练数据集中到达的深度和行数来做到这一点。\n",
    "\n",
    "最大树深度：这是从树的根节点开始的最大节点数。一旦满足树的最大深度，我们必须停止分裂添加新节点。更深的树更复杂，更可能过拟合训练数据。\n",
    "\n",
    "最小节点数：这是给定节点负责的训练模式的最小数量。 一旦达到或低于此最小值，我们必须停止拆分和添加新节点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.2、递归划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # 不再划分\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # 最大深度\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # 左子树\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    # 右子树\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.3、创建决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(dataset)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "这里再增加一个print_tree()函数，它递归地打印出决策树的节点，每个节点一行。 虽然不如真正的决策树图那么直观，但是它给出了决策树的基本生成思路。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print ('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print ('%s[%s]' % ((depth*' ', node)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以设计一个小数据集来查看我们的决策树是如何生成的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 < 2.771 Gini=0.494\n",
      "X1 < 1.729 Gini=0.500\n",
      "X1 < 3.678 Gini=0.408\n",
      "X1 < 3.961 Gini=0.278\n",
      "X1 < 2.999 Gini=0.469\n",
      "X1 < 7.498 Gini=0.408\n",
      "X1 < 9.002 Gini=0.469\n",
      "X1 < 7.445 Gini=0.278\n",
      "X1 < 10.125 Gini=0.494\n",
      "X1 < 6.642 Gini=0.000\n",
      "X2 < 1.785 Gini=1.000\n",
      "X2 < 1.170 Gini=0.494\n",
      "X2 < 2.813 Gini=0.640\n",
      "X2 < 2.620 Gini=0.819\n",
      "X2 < 2.209 Gini=0.934\n",
      "X2 < 3.163 Gini=0.278\n",
      "X2 < 3.339 Gini=0.494\n",
      "X2 < 0.477 Gini=0.500\n",
      "X2 < 3.235 Gini=0.408\n",
      "X2 < 3.320 Gini=0.469\n",
      "[X1 < 6.642]\n",
      " [0]\n",
      " [1]\n"
     ]
    }
   ],
   "source": [
    "dataset = [[2.771244718,1.784783929,0],\n",
    "    [1.728571309,1.169761413,0],\n",
    "    [3.678319846,2.81281357,0],\n",
    "    [3.961043357,2.61995032,0],\n",
    "    [2.999208922,2.209014212,0],\n",
    "    [7.497545867,3.162953546,1],\n",
    "    [9.00220326,3.339047188,1],\n",
    "    [7.444542326,0.476683375,1],\n",
    "    [10.12493903,3.234550982,1],\n",
    "    [6.642287351,3.319983761,1]]\n",
    "tree = build_tree(dataset, 1, 1)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、作出预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以设计一个小数据集来使用决策树预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=0, Got=0\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n",
      "Expected=1, Got=1\n"
     ]
    }
   ],
   "source": [
    "dataset = [[2.771244718,1.784783929,0],\n",
    "    [1.728571309,1.169761413,0],\n",
    "    [3.678319846,2.81281357,0],\n",
    "    [3.961043357,2.61995032,0],\n",
    "    [2.999208922,2.209014212,0],\n",
    "    [7.497545867,3.162953546,1],\n",
    "    [9.00220326,3.339047188,1],\n",
    "    [7.444542326,0.476683375,1],\n",
    "    [10.12493903,3.234550982,1],\n",
    "    [6.642287351,3.319983761,1]]\n",
    " \n",
    "stump = {'index': 0, 'right': 1, 'value': 6.642287351, 'left': 0}\n",
    "for row in dataset:\n",
    "    prediction = predict(stump, row)\n",
    "    print ('Expected=%d, Got=%d' % (row[-1], prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
