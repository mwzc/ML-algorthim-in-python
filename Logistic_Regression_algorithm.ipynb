{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 使用Python实现Logistic Regression算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逻辑回归使用方程作为表示，非常像线性回归。 使用权重或系数值线性地组合输入值（X）以预测输出值（y）。\n",
    "\n",
    "与线性回归的主要区别是，建模后的输出值是二进制值（0或1），而不是数值。\n",
    "\n",
    "yhat = 1.0 / (1.0 + e^(-(b0 + b1 * x1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、作出预测\n",
    "\n",
    "第一步是建立一个可以进行预测的函数。\n",
    "\n",
    "这将需要在随机梯度下降中的候选系数和模型被最终确定之后，我们希望开始对测试数据或新数据进行预测。\n",
    "\n",
    "第一个系数始终是截距，也称为偏差或b0，因为它是独立的，不是由输入值确定的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def predict(row, coefficients):\n",
    "    y = coefficients[0]\n",
    "    for i in range(len(row)-1):\n",
    "        y += coefficients[i+1] * row[i]\n",
    "    return 1.0 / (1.0 + math.exp(-y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以设计一个小数据集来测试我们的predict()函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=0.000, Predicted=0.299 [0]\n",
      "Expected=0.000, Predicted=0.146 [0]\n",
      "Expected=0.000, Predicted=0.085 [0]\n",
      "Expected=0.000, Predicted=0.220 [0]\n",
      "Expected=0.000, Predicted=0.247 [0]\n",
      "Expected=1.000, Predicted=0.955 [1]\n",
      "Expected=1.000, Predicted=0.862 [1]\n",
      "Expected=1.000, Predicted=0.972 [1]\n",
      "Expected=1.000, Predicted=0.999 [1]\n",
      "Expected=1.000, Predicted=0.905 [1]\n"
     ]
    }
   ],
   "source": [
    "dataset = [[2.7810836,2.550537003,0],\n",
    "    [1.465489372,2.362125076,0],\n",
    "    [3.396561688,4.400293529,0],\n",
    "    [1.38807019,1.850220317,0],\n",
    "    [3.06407232,3.005305973,0],\n",
    "    [7.627531214,2.759262235,1],\n",
    "    [5.332441248,2.088626775,1],\n",
    "    [6.922596716,1.77106367,1],\n",
    "    [8.675418651,-0.242068655,1],\n",
    "    [7.673756466,3.508563011,1]]\n",
    "coef = [-0.406605464, 0.852573316, -1.104746259]\n",
    "for row in dataset:\n",
    "    y = predict(row, coef)\n",
    "    print(\"Expected=%.3f, Predicted=%.3f [%d]\" % (row[-1], y, round(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、计算参数\n",
    "\n",
    "我们可以根据训练数据使用随机梯度下降来估计的系数值。\n",
    "\n",
    "随机梯度下降需要两个参数：\n",
    "\n",
    "Learning Rate：用于限制每次更新时的步长。\n",
    "\n",
    "Epochs：迭代的总次数\n",
    "\n",
    "在函数中需要执行3个循环：\n",
    "\n",
    "1、循环每一次迭代\n",
    "\n",
    "2、在训练数据上的每一行循环\n",
    "\n",
    "3、循环每个系数并更新。\n",
    "\n",
    "有一个系数用于对每个输入属性进行加权，并以一致的方式更新这些属性，例如：\n",
    "b1(t+1) = b1(t) + learning_rate * (y(t) - yhat(t)) * yhat(t) * (1 - yhat(t)) * x1(t)\n",
    "\n",
    "截距以类似的方式更新，除了没有输入，因为它不与特定输入值相关联：\n",
    "b0(t+1) = b0(t) + learning_rate * (y(t) - yhat(t)) * yhat(t) * (1 - yhat(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "    coef = [0.0 for i in range(len(train[0]))]\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            y = predict(row, coef)\n",
    "            error = row[-1] - y\n",
    "            sum_error += error ** 2\n",
    "            coef[0] = coef[0] + l_rate * error * y * (1.0 - y)\n",
    "            for i in range(len(row)-1):\n",
    "                coef[i+1] = coef[i+1] + l_rate * error * y * (1.0 - y) * row[i]\n",
    "        print (('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error)))\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以设计一个小数据集来测试我们的coefficients_sgd()函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.300, error=2.217\n",
      ">epoch=1, lrate=0.300, error=1.613\n",
      ">epoch=2, lrate=0.300, error=1.113\n",
      ">epoch=3, lrate=0.300, error=0.827\n",
      ">epoch=4, lrate=0.300, error=0.623\n",
      ">epoch=5, lrate=0.300, error=0.494\n",
      ">epoch=6, lrate=0.300, error=0.412\n",
      ">epoch=7, lrate=0.300, error=0.354\n",
      ">epoch=8, lrate=0.300, error=0.310\n",
      ">epoch=9, lrate=0.300, error=0.276\n",
      ">epoch=10, lrate=0.300, error=0.248\n",
      ">epoch=11, lrate=0.300, error=0.224\n",
      ">epoch=12, lrate=0.300, error=0.205\n",
      ">epoch=13, lrate=0.300, error=0.189\n",
      ">epoch=14, lrate=0.300, error=0.174\n",
      ">epoch=15, lrate=0.300, error=0.162\n",
      ">epoch=16, lrate=0.300, error=0.151\n",
      ">epoch=17, lrate=0.300, error=0.142\n",
      ">epoch=18, lrate=0.300, error=0.134\n",
      ">epoch=19, lrate=0.300, error=0.126\n",
      ">epoch=20, lrate=0.300, error=0.119\n",
      ">epoch=21, lrate=0.300, error=0.113\n",
      ">epoch=22, lrate=0.300, error=0.108\n",
      ">epoch=23, lrate=0.300, error=0.103\n",
      ">epoch=24, lrate=0.300, error=0.098\n",
      ">epoch=25, lrate=0.300, error=0.094\n",
      ">epoch=26, lrate=0.300, error=0.090\n",
      ">epoch=27, lrate=0.300, error=0.087\n",
      ">epoch=28, lrate=0.300, error=0.084\n",
      ">epoch=29, lrate=0.300, error=0.080\n",
      ">epoch=30, lrate=0.300, error=0.078\n",
      ">epoch=31, lrate=0.300, error=0.075\n",
      ">epoch=32, lrate=0.300, error=0.073\n",
      ">epoch=33, lrate=0.300, error=0.070\n",
      ">epoch=34, lrate=0.300, error=0.068\n",
      ">epoch=35, lrate=0.300, error=0.066\n",
      ">epoch=36, lrate=0.300, error=0.064\n",
      ">epoch=37, lrate=0.300, error=0.062\n",
      ">epoch=38, lrate=0.300, error=0.060\n",
      ">epoch=39, lrate=0.300, error=0.059\n",
      ">epoch=40, lrate=0.300, error=0.057\n",
      ">epoch=41, lrate=0.300, error=0.056\n",
      ">epoch=42, lrate=0.300, error=0.054\n",
      ">epoch=43, lrate=0.300, error=0.053\n",
      ">epoch=44, lrate=0.300, error=0.052\n",
      ">epoch=45, lrate=0.300, error=0.051\n",
      ">epoch=46, lrate=0.300, error=0.050\n",
      ">epoch=47, lrate=0.300, error=0.048\n",
      ">epoch=48, lrate=0.300, error=0.047\n",
      ">epoch=49, lrate=0.300, error=0.046\n",
      ">epoch=50, lrate=0.300, error=0.045\n",
      ">epoch=51, lrate=0.300, error=0.044\n",
      ">epoch=52, lrate=0.300, error=0.044\n",
      ">epoch=53, lrate=0.300, error=0.043\n",
      ">epoch=54, lrate=0.300, error=0.042\n",
      ">epoch=55, lrate=0.300, error=0.041\n",
      ">epoch=56, lrate=0.300, error=0.040\n",
      ">epoch=57, lrate=0.300, error=0.040\n",
      ">epoch=58, lrate=0.300, error=0.039\n",
      ">epoch=59, lrate=0.300, error=0.038\n",
      ">epoch=60, lrate=0.300, error=0.038\n",
      ">epoch=61, lrate=0.300, error=0.037\n",
      ">epoch=62, lrate=0.300, error=0.036\n",
      ">epoch=63, lrate=0.300, error=0.036\n",
      ">epoch=64, lrate=0.300, error=0.035\n",
      ">epoch=65, lrate=0.300, error=0.035\n",
      ">epoch=66, lrate=0.300, error=0.034\n",
      ">epoch=67, lrate=0.300, error=0.033\n",
      ">epoch=68, lrate=0.300, error=0.033\n",
      ">epoch=69, lrate=0.300, error=0.032\n",
      ">epoch=70, lrate=0.300, error=0.032\n",
      ">epoch=71, lrate=0.300, error=0.032\n",
      ">epoch=72, lrate=0.300, error=0.031\n",
      ">epoch=73, lrate=0.300, error=0.031\n",
      ">epoch=74, lrate=0.300, error=0.030\n",
      ">epoch=75, lrate=0.300, error=0.030\n",
      ">epoch=76, lrate=0.300, error=0.029\n",
      ">epoch=77, lrate=0.300, error=0.029\n",
      ">epoch=78, lrate=0.300, error=0.029\n",
      ">epoch=79, lrate=0.300, error=0.028\n",
      ">epoch=80, lrate=0.300, error=0.028\n",
      ">epoch=81, lrate=0.300, error=0.027\n",
      ">epoch=82, lrate=0.300, error=0.027\n",
      ">epoch=83, lrate=0.300, error=0.027\n",
      ">epoch=84, lrate=0.300, error=0.026\n",
      ">epoch=85, lrate=0.300, error=0.026\n",
      ">epoch=86, lrate=0.300, error=0.026\n",
      ">epoch=87, lrate=0.300, error=0.026\n",
      ">epoch=88, lrate=0.300, error=0.025\n",
      ">epoch=89, lrate=0.300, error=0.025\n",
      ">epoch=90, lrate=0.300, error=0.025\n",
      ">epoch=91, lrate=0.300, error=0.024\n",
      ">epoch=92, lrate=0.300, error=0.024\n",
      ">epoch=93, lrate=0.300, error=0.024\n",
      ">epoch=94, lrate=0.300, error=0.024\n",
      ">epoch=95, lrate=0.300, error=0.023\n",
      ">epoch=96, lrate=0.300, error=0.023\n",
      ">epoch=97, lrate=0.300, error=0.023\n",
      ">epoch=98, lrate=0.300, error=0.023\n",
      ">epoch=99, lrate=0.300, error=0.022\n",
      "[-0.8596443546618897, 1.5223825112460005, -2.218700210565016]\n"
     ]
    }
   ],
   "source": [
    "dataset = [[2.7810836,2.550537003,0],\n",
    "    [1.465489372,2.362125076,0],\n",
    "    [3.396561688,4.400293529,0],\n",
    "    [1.38807019,1.850220317,0],\n",
    "    [3.06407232,3.005305973,0],\n",
    "    [7.627531214,2.759262235,1],\n",
    "    [5.332441248,2.088626775,1],\n",
    "    [6.922596716,1.77106367,1],\n",
    "    [8.675418651,-0.242068655,1],\n",
    "    [7.673756466,3.508563011,1]]\n",
    "l_rate = 0.3\n",
    "n_epoch = 100\n",
    "coef = coefficients_sgd(dataset, l_rate, n_epoch)\n",
    "print ((coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression算法的完整代码如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.100, error=139.813\n",
      ">epoch=1, lrate=0.100, error=133.309\n",
      ">epoch=2, lrate=0.100, error=128.382\n",
      ">epoch=3, lrate=0.100, error=124.424\n",
      ">epoch=4, lrate=0.100, error=121.213\n",
      ">epoch=5, lrate=0.100, error=118.571\n",
      ">epoch=6, lrate=0.100, error=116.362\n",
      ">epoch=7, lrate=0.100, error=114.487\n",
      ">epoch=8, lrate=0.100, error=112.875\n",
      ">epoch=9, lrate=0.100, error=111.473\n",
      ">epoch=10, lrate=0.100, error=110.240\n",
      ">epoch=11, lrate=0.100, error=109.148\n",
      ">epoch=12, lrate=0.100, error=108.172\n",
      ">epoch=13, lrate=0.100, error=107.294\n",
      ">epoch=14, lrate=0.100, error=106.501\n",
      ">epoch=15, lrate=0.100, error=105.780\n",
      ">epoch=16, lrate=0.100, error=105.122\n",
      ">epoch=17, lrate=0.100, error=104.518\n",
      ">epoch=18, lrate=0.100, error=103.963\n",
      ">epoch=19, lrate=0.100, error=103.450\n",
      ">epoch=20, lrate=0.100, error=102.975\n",
      ">epoch=21, lrate=0.100, error=102.533\n",
      ">epoch=22, lrate=0.100, error=102.122\n",
      ">epoch=23, lrate=0.100, error=101.739\n",
      ">epoch=24, lrate=0.100, error=101.380\n",
      ">epoch=25, lrate=0.100, error=101.044\n",
      ">epoch=26, lrate=0.100, error=100.728\n",
      ">epoch=27, lrate=0.100, error=100.431\n",
      ">epoch=28, lrate=0.100, error=100.152\n",
      ">epoch=29, lrate=0.100, error=99.888\n",
      ">epoch=30, lrate=0.100, error=99.638\n",
      ">epoch=31, lrate=0.100, error=99.402\n",
      ">epoch=32, lrate=0.100, error=99.179\n",
      ">epoch=33, lrate=0.100, error=98.967\n",
      ">epoch=34, lrate=0.100, error=98.765\n",
      ">epoch=35, lrate=0.100, error=98.574\n",
      ">epoch=36, lrate=0.100, error=98.392\n",
      ">epoch=37, lrate=0.100, error=98.218\n",
      ">epoch=38, lrate=0.100, error=98.053\n",
      ">epoch=39, lrate=0.100, error=97.895\n",
      ">epoch=40, lrate=0.100, error=97.745\n",
      ">epoch=41, lrate=0.100, error=97.601\n",
      ">epoch=42, lrate=0.100, error=97.463\n",
      ">epoch=43, lrate=0.100, error=97.331\n",
      ">epoch=44, lrate=0.100, error=97.205\n",
      ">epoch=45, lrate=0.100, error=97.085\n",
      ">epoch=46, lrate=0.100, error=96.969\n",
      ">epoch=47, lrate=0.100, error=96.858\n",
      ">epoch=48, lrate=0.100, error=96.751\n",
      ">epoch=49, lrate=0.100, error=96.649\n",
      ">epoch=50, lrate=0.100, error=96.550\n",
      ">epoch=51, lrate=0.100, error=96.456\n",
      ">epoch=52, lrate=0.100, error=96.365\n",
      ">epoch=53, lrate=0.100, error=96.277\n",
      ">epoch=54, lrate=0.100, error=96.193\n",
      ">epoch=55, lrate=0.100, error=96.112\n",
      ">epoch=56, lrate=0.100, error=96.033\n",
      ">epoch=57, lrate=0.100, error=95.958\n",
      ">epoch=58, lrate=0.100, error=95.885\n",
      ">epoch=59, lrate=0.100, error=95.815\n",
      ">epoch=60, lrate=0.100, error=95.747\n",
      ">epoch=61, lrate=0.100, error=95.682\n",
      ">epoch=62, lrate=0.100, error=95.619\n",
      ">epoch=63, lrate=0.100, error=95.557\n",
      ">epoch=64, lrate=0.100, error=95.498\n",
      ">epoch=65, lrate=0.100, error=95.441\n",
      ">epoch=66, lrate=0.100, error=95.386\n",
      ">epoch=67, lrate=0.100, error=95.333\n",
      ">epoch=68, lrate=0.100, error=95.281\n",
      ">epoch=69, lrate=0.100, error=95.231\n",
      ">epoch=70, lrate=0.100, error=95.182\n",
      ">epoch=71, lrate=0.100, error=95.135\n",
      ">epoch=72, lrate=0.100, error=95.090\n",
      ">epoch=73, lrate=0.100, error=95.046\n",
      ">epoch=74, lrate=0.100, error=95.003\n",
      ">epoch=75, lrate=0.100, error=94.961\n",
      ">epoch=76, lrate=0.100, error=94.921\n",
      ">epoch=77, lrate=0.100, error=94.882\n",
      ">epoch=78, lrate=0.100, error=94.844\n",
      ">epoch=79, lrate=0.100, error=94.807\n",
      ">epoch=80, lrate=0.100, error=94.771\n",
      ">epoch=81, lrate=0.100, error=94.737\n",
      ">epoch=82, lrate=0.100, error=94.703\n",
      ">epoch=83, lrate=0.100, error=94.670\n",
      ">epoch=84, lrate=0.100, error=94.638\n",
      ">epoch=85, lrate=0.100, error=94.607\n",
      ">epoch=86, lrate=0.100, error=94.577\n",
      ">epoch=87, lrate=0.100, error=94.548\n",
      ">epoch=88, lrate=0.100, error=94.519\n",
      ">epoch=89, lrate=0.100, error=94.492\n",
      ">epoch=90, lrate=0.100, error=94.465\n",
      ">epoch=91, lrate=0.100, error=94.438\n",
      ">epoch=92, lrate=0.100, error=94.413\n",
      ">epoch=93, lrate=0.100, error=94.388\n",
      ">epoch=94, lrate=0.100, error=94.364\n",
      ">epoch=95, lrate=0.100, error=94.340\n",
      ">epoch=96, lrate=0.100, error=94.317\n",
      ">epoch=97, lrate=0.100, error=94.295\n",
      ">epoch=98, lrate=0.100, error=94.273\n",
      ">epoch=99, lrate=0.100, error=94.251\n",
      ">epoch=0, lrate=0.100, error=141.059\n",
      ">epoch=1, lrate=0.100, error=134.317\n",
      ">epoch=2, lrate=0.100, error=129.498\n",
      ">epoch=3, lrate=0.100, error=125.620\n",
      ">epoch=4, lrate=0.100, error=122.461\n",
      ">epoch=5, lrate=0.100, error=119.847\n",
      ">epoch=6, lrate=0.100, error=117.648\n",
      ">epoch=7, lrate=0.100, error=115.771\n",
      ">epoch=8, lrate=0.100, error=114.149\n",
      ">epoch=9, lrate=0.100, error=112.730\n",
      ">epoch=10, lrate=0.100, error=111.477\n",
      ">epoch=11, lrate=0.100, error=110.363\n",
      ">epoch=12, lrate=0.100, error=109.364\n",
      ">epoch=13, lrate=0.100, error=108.464\n",
      ">epoch=14, lrate=0.100, error=107.649\n",
      ">epoch=15, lrate=0.100, error=106.906\n",
      ">epoch=16, lrate=0.100, error=106.227\n",
      ">epoch=17, lrate=0.100, error=105.603\n",
      ">epoch=18, lrate=0.100, error=105.029\n",
      ">epoch=19, lrate=0.100, error=104.498\n",
      ">epoch=20, lrate=0.100, error=104.007\n",
      ">epoch=21, lrate=0.100, error=103.550\n",
      ">epoch=22, lrate=0.100, error=103.125\n",
      ">epoch=23, lrate=0.100, error=102.728\n",
      ">epoch=24, lrate=0.100, error=102.357\n",
      ">epoch=25, lrate=0.100, error=102.009\n",
      ">epoch=26, lrate=0.100, error=101.683\n",
      ">epoch=27, lrate=0.100, error=101.376\n",
      ">epoch=28, lrate=0.100, error=101.087\n",
      ">epoch=29, lrate=0.100, error=100.815\n",
      ">epoch=30, lrate=0.100, error=100.557\n",
      ">epoch=31, lrate=0.100, error=100.314\n",
      ">epoch=32, lrate=0.100, error=100.083\n",
      ">epoch=33, lrate=0.100, error=99.865\n",
      ">epoch=34, lrate=0.100, error=99.657\n",
      ">epoch=35, lrate=0.100, error=99.460\n",
      ">epoch=36, lrate=0.100, error=99.273\n",
      ">epoch=37, lrate=0.100, error=99.095\n",
      ">epoch=38, lrate=0.100, error=98.925\n",
      ">epoch=39, lrate=0.100, error=98.763\n",
      ">epoch=40, lrate=0.100, error=98.608\n",
      ">epoch=41, lrate=0.100, error=98.460\n",
      ">epoch=42, lrate=0.100, error=98.319\n",
      ">epoch=43, lrate=0.100, error=98.184\n",
      ">epoch=44, lrate=0.100, error=98.055\n",
      ">epoch=45, lrate=0.100, error=97.931\n",
      ">epoch=46, lrate=0.100, error=97.812\n",
      ">epoch=47, lrate=0.100, error=97.698\n",
      ">epoch=48, lrate=0.100, error=97.589\n",
      ">epoch=49, lrate=0.100, error=97.484\n",
      ">epoch=50, lrate=0.100, error=97.383\n",
      ">epoch=51, lrate=0.100, error=97.286\n",
      ">epoch=52, lrate=0.100, error=97.193\n",
      ">epoch=53, lrate=0.100, error=97.103\n",
      ">epoch=54, lrate=0.100, error=97.017\n",
      ">epoch=55, lrate=0.100, error=96.933\n",
      ">epoch=56, lrate=0.100, error=96.853\n",
      ">epoch=57, lrate=0.100, error=96.776\n",
      ">epoch=58, lrate=0.100, error=96.701\n",
      ">epoch=59, lrate=0.100, error=96.629\n",
      ">epoch=60, lrate=0.100, error=96.559\n",
      ">epoch=61, lrate=0.100, error=96.492\n",
      ">epoch=62, lrate=0.100, error=96.427\n",
      ">epoch=63, lrate=0.100, error=96.364\n",
      ">epoch=64, lrate=0.100, error=96.303\n",
      ">epoch=65, lrate=0.100, error=96.245\n",
      ">epoch=66, lrate=0.100, error=96.188\n",
      ">epoch=67, lrate=0.100, error=96.133\n",
      ">epoch=68, lrate=0.100, error=96.079\n",
      ">epoch=69, lrate=0.100, error=96.028\n",
      ">epoch=70, lrate=0.100, error=95.978\n",
      ">epoch=71, lrate=0.100, error=95.929\n",
      ">epoch=72, lrate=0.100, error=95.882\n",
      ">epoch=73, lrate=0.100, error=95.836\n",
      ">epoch=74, lrate=0.100, error=95.792\n",
      ">epoch=75, lrate=0.100, error=95.749\n",
      ">epoch=76, lrate=0.100, error=95.707\n",
      ">epoch=77, lrate=0.100, error=95.667\n",
      ">epoch=78, lrate=0.100, error=95.627\n",
      ">epoch=79, lrate=0.100, error=95.589\n",
      ">epoch=80, lrate=0.100, error=95.552\n",
      ">epoch=81, lrate=0.100, error=95.516\n",
      ">epoch=82, lrate=0.100, error=95.481\n",
      ">epoch=83, lrate=0.100, error=95.447\n",
      ">epoch=84, lrate=0.100, error=95.413\n",
      ">epoch=85, lrate=0.100, error=95.381\n",
      ">epoch=86, lrate=0.100, error=95.349\n",
      ">epoch=87, lrate=0.100, error=95.319\n",
      ">epoch=88, lrate=0.100, error=95.289\n",
      ">epoch=89, lrate=0.100, error=95.260\n",
      ">epoch=90, lrate=0.100, error=95.232\n",
      ">epoch=91, lrate=0.100, error=95.204\n",
      ">epoch=92, lrate=0.100, error=95.177\n",
      ">epoch=93, lrate=0.100, error=95.151\n",
      ">epoch=94, lrate=0.100, error=95.126\n",
      ">epoch=95, lrate=0.100, error=95.101\n",
      ">epoch=96, lrate=0.100, error=95.076\n",
      ">epoch=97, lrate=0.100, error=95.053\n",
      ">epoch=98, lrate=0.100, error=95.030\n",
      ">epoch=99, lrate=0.100, error=95.007\n",
      ">epoch=0, lrate=0.100, error=140.806\n",
      ">epoch=1, lrate=0.100, error=134.124\n",
      ">epoch=2, lrate=0.100, error=129.283\n",
      ">epoch=3, lrate=0.100, error=125.355\n",
      ">epoch=4, lrate=0.100, error=122.142\n",
      ">epoch=5, lrate=0.100, error=119.481\n",
      ">epoch=6, lrate=0.100, error=117.246\n",
      ">epoch=7, lrate=0.100, error=115.345\n",
      ">epoch=8, lrate=0.100, error=113.711\n",
      ">epoch=9, lrate=0.100, error=112.290\n",
      ">epoch=10, lrate=0.100, error=111.044\n",
      ">epoch=11, lrate=0.100, error=109.943\n",
      ">epoch=12, lrate=0.100, error=108.964\n",
      ">epoch=13, lrate=0.100, error=108.087\n",
      ">epoch=14, lrate=0.100, error=107.298\n",
      ">epoch=15, lrate=0.100, error=106.585\n",
      ">epoch=16, lrate=0.100, error=105.937\n",
      ">epoch=17, lrate=0.100, error=105.346\n",
      ">epoch=18, lrate=0.100, error=104.806\n",
      ">epoch=19, lrate=0.100, error=104.310\n",
      ">epoch=20, lrate=0.100, error=103.853\n",
      ">epoch=21, lrate=0.100, error=103.432\n",
      ">epoch=22, lrate=0.100, error=103.041\n",
      ">epoch=23, lrate=0.100, error=102.679\n",
      ">epoch=24, lrate=0.100, error=102.342\n",
      ">epoch=25, lrate=0.100, error=102.028\n",
      ">epoch=26, lrate=0.100, error=101.734\n",
      ">epoch=27, lrate=0.100, error=101.459\n",
      ">epoch=28, lrate=0.100, error=101.202\n",
      ">epoch=29, lrate=0.100, error=100.960\n",
      ">epoch=30, lrate=0.100, error=100.733\n",
      ">epoch=31, lrate=0.100, error=100.519\n",
      ">epoch=32, lrate=0.100, error=100.317\n",
      ">epoch=33, lrate=0.100, error=100.126\n",
      ">epoch=34, lrate=0.100, error=99.946\n",
      ">epoch=35, lrate=0.100, error=99.775\n",
      ">epoch=36, lrate=0.100, error=99.613\n",
      ">epoch=37, lrate=0.100, error=99.459\n",
      ">epoch=38, lrate=0.100, error=99.314\n",
      ">epoch=39, lrate=0.100, error=99.175\n",
      ">epoch=40, lrate=0.100, error=99.043\n",
      ">epoch=41, lrate=0.100, error=98.917\n",
      ">epoch=42, lrate=0.100, error=98.798\n",
      ">epoch=43, lrate=0.100, error=98.683\n",
      ">epoch=44, lrate=0.100, error=98.574\n",
      ">epoch=45, lrate=0.100, error=98.470\n",
      ">epoch=46, lrate=0.100, error=98.370\n",
      ">epoch=47, lrate=0.100, error=98.275\n",
      ">epoch=48, lrate=0.100, error=98.184\n",
      ">epoch=49, lrate=0.100, error=98.096\n",
      ">epoch=50, lrate=0.100, error=98.013\n",
      ">epoch=51, lrate=0.100, error=97.932\n",
      ">epoch=52, lrate=0.100, error=97.855\n",
      ">epoch=53, lrate=0.100, error=97.781\n",
      ">epoch=54, lrate=0.100, error=97.710\n",
      ">epoch=55, lrate=0.100, error=97.642\n",
      ">epoch=56, lrate=0.100, error=97.576\n",
      ">epoch=57, lrate=0.100, error=97.513\n",
      ">epoch=58, lrate=0.100, error=97.452\n",
      ">epoch=59, lrate=0.100, error=97.394\n",
      ">epoch=60, lrate=0.100, error=97.337\n",
      ">epoch=61, lrate=0.100, error=97.283\n",
      ">epoch=62, lrate=0.100, error=97.230\n",
      ">epoch=63, lrate=0.100, error=97.180\n",
      ">epoch=64, lrate=0.100, error=97.131\n",
      ">epoch=65, lrate=0.100, error=97.084\n",
      ">epoch=66, lrate=0.100, error=97.039\n",
      ">epoch=67, lrate=0.100, error=96.995\n",
      ">epoch=68, lrate=0.100, error=96.953\n",
      ">epoch=69, lrate=0.100, error=96.912\n",
      ">epoch=70, lrate=0.100, error=96.872\n",
      ">epoch=71, lrate=0.100, error=96.834\n",
      ">epoch=72, lrate=0.100, error=96.797\n",
      ">epoch=73, lrate=0.100, error=96.761\n",
      ">epoch=74, lrate=0.100, error=96.727\n",
      ">epoch=75, lrate=0.100, error=96.693\n",
      ">epoch=76, lrate=0.100, error=96.661\n",
      ">epoch=77, lrate=0.100, error=96.629\n",
      ">epoch=78, lrate=0.100, error=96.599\n",
      ">epoch=79, lrate=0.100, error=96.570\n",
      ">epoch=80, lrate=0.100, error=96.541\n",
      ">epoch=81, lrate=0.100, error=96.513\n",
      ">epoch=82, lrate=0.100, error=96.486\n",
      ">epoch=83, lrate=0.100, error=96.460\n",
      ">epoch=84, lrate=0.100, error=96.435\n",
      ">epoch=85, lrate=0.100, error=96.411\n",
      ">epoch=86, lrate=0.100, error=96.387\n",
      ">epoch=87, lrate=0.100, error=96.364\n",
      ">epoch=88, lrate=0.100, error=96.341\n",
      ">epoch=89, lrate=0.100, error=96.320\n",
      ">epoch=90, lrate=0.100, error=96.298\n",
      ">epoch=91, lrate=0.100, error=96.278\n",
      ">epoch=92, lrate=0.100, error=96.258\n",
      ">epoch=93, lrate=0.100, error=96.239\n",
      ">epoch=94, lrate=0.100, error=96.220\n",
      ">epoch=95, lrate=0.100, error=96.201\n",
      ">epoch=96, lrate=0.100, error=96.184\n",
      ">epoch=97, lrate=0.100, error=96.166\n",
      ">epoch=98, lrate=0.100, error=96.149\n",
      ">epoch=99, lrate=0.100, error=96.133\n",
      ">epoch=0, lrate=0.100, error=140.723\n",
      ">epoch=1, lrate=0.100, error=133.858\n",
      ">epoch=2, lrate=0.100, error=128.943\n",
      ">epoch=3, lrate=0.100, error=124.999\n",
      ">epoch=4, lrate=0.100, error=121.794\n",
      ">epoch=5, lrate=0.100, error=119.146\n",
      ">epoch=6, lrate=0.100, error=116.921\n",
      ">epoch=7, lrate=0.100, error=115.023\n",
      ">epoch=8, lrate=0.100, error=113.382\n",
      ">epoch=9, lrate=0.100, error=111.948\n",
      ">epoch=10, lrate=0.100, error=110.682\n",
      ">epoch=11, lrate=0.100, error=109.556\n",
      ">epoch=12, lrate=0.100, error=108.548\n",
      ">epoch=13, lrate=0.100, error=107.641\n",
      ">epoch=14, lrate=0.100, error=106.819\n",
      ">epoch=15, lrate=0.100, error=106.072\n",
      ">epoch=16, lrate=0.100, error=105.391\n",
      ">epoch=17, lrate=0.100, error=104.766\n",
      ">epoch=18, lrate=0.100, error=104.192\n",
      ">epoch=19, lrate=0.100, error=103.663\n",
      ">epoch=20, lrate=0.100, error=103.174\n",
      ">epoch=21, lrate=0.100, error=102.721\n",
      ">epoch=22, lrate=0.100, error=102.300\n",
      ">epoch=23, lrate=0.100, error=101.907\n",
      ">epoch=24, lrate=0.100, error=101.542\n",
      ">epoch=25, lrate=0.100, error=101.200\n",
      ">epoch=26, lrate=0.100, error=100.879\n",
      ">epoch=27, lrate=0.100, error=100.578\n",
      ">epoch=28, lrate=0.100, error=100.296\n",
      ">epoch=29, lrate=0.100, error=100.030\n",
      ">epoch=30, lrate=0.100, error=99.779\n",
      ">epoch=31, lrate=0.100, error=99.542\n",
      ">epoch=32, lrate=0.100, error=99.319\n",
      ">epoch=33, lrate=0.100, error=99.107\n",
      ">epoch=34, lrate=0.100, error=98.906\n",
      ">epoch=35, lrate=0.100, error=98.716\n",
      ">epoch=36, lrate=0.100, error=98.535\n",
      ">epoch=37, lrate=0.100, error=98.363\n",
      ">epoch=38, lrate=0.100, error=98.199\n",
      ">epoch=39, lrate=0.100, error=98.043\n",
      ">epoch=40, lrate=0.100, error=97.895\n",
      ">epoch=41, lrate=0.100, error=97.753\n",
      ">epoch=42, lrate=0.100, error=97.617\n",
      ">epoch=43, lrate=0.100, error=97.488\n",
      ">epoch=44, lrate=0.100, error=97.364\n",
      ">epoch=45, lrate=0.100, error=97.245\n",
      ">epoch=46, lrate=0.100, error=97.132\n",
      ">epoch=47, lrate=0.100, error=97.023\n",
      ">epoch=48, lrate=0.100, error=96.919\n",
      ">epoch=49, lrate=0.100, error=96.819\n",
      ">epoch=50, lrate=0.100, error=96.723\n",
      ">epoch=51, lrate=0.100, error=96.630\n",
      ">epoch=52, lrate=0.100, error=96.541\n",
      ">epoch=53, lrate=0.100, error=96.456\n",
      ">epoch=54, lrate=0.100, error=96.374\n",
      ">epoch=55, lrate=0.100, error=96.295\n",
      ">epoch=56, lrate=0.100, error=96.218\n",
      ">epoch=57, lrate=0.100, error=96.145\n",
      ">epoch=58, lrate=0.100, error=96.074\n",
      ">epoch=59, lrate=0.100, error=96.006\n",
      ">epoch=60, lrate=0.100, error=95.940\n",
      ">epoch=61, lrate=0.100, error=95.876\n",
      ">epoch=62, lrate=0.100, error=95.815\n",
      ">epoch=63, lrate=0.100, error=95.755\n",
      ">epoch=64, lrate=0.100, error=95.698\n",
      ">epoch=65, lrate=0.100, error=95.643\n",
      ">epoch=66, lrate=0.100, error=95.589\n",
      ">epoch=67, lrate=0.100, error=95.537\n",
      ">epoch=68, lrate=0.100, error=95.487\n",
      ">epoch=69, lrate=0.100, error=95.438\n",
      ">epoch=70, lrate=0.100, error=95.391\n",
      ">epoch=71, lrate=0.100, error=95.345\n",
      ">epoch=72, lrate=0.100, error=95.301\n",
      ">epoch=73, lrate=0.100, error=95.258\n",
      ">epoch=74, lrate=0.100, error=95.217\n",
      ">epoch=75, lrate=0.100, error=95.176\n",
      ">epoch=76, lrate=0.100, error=95.137\n",
      ">epoch=77, lrate=0.100, error=95.099\n",
      ">epoch=78, lrate=0.100, error=95.063\n",
      ">epoch=79, lrate=0.100, error=95.027\n",
      ">epoch=80, lrate=0.100, error=94.992\n",
      ">epoch=81, lrate=0.100, error=94.958\n",
      ">epoch=82, lrate=0.100, error=94.925\n",
      ">epoch=83, lrate=0.100, error=94.894\n",
      ">epoch=84, lrate=0.100, error=94.863\n",
      ">epoch=85, lrate=0.100, error=94.832\n",
      ">epoch=86, lrate=0.100, error=94.803\n",
      ">epoch=87, lrate=0.100, error=94.775\n",
      ">epoch=88, lrate=0.100, error=94.747\n",
      ">epoch=89, lrate=0.100, error=94.720\n",
      ">epoch=90, lrate=0.100, error=94.694\n",
      ">epoch=91, lrate=0.100, error=94.668\n",
      ">epoch=92, lrate=0.100, error=94.643\n",
      ">epoch=93, lrate=0.100, error=94.619\n",
      ">epoch=94, lrate=0.100, error=94.595\n",
      ">epoch=95, lrate=0.100, error=94.572\n",
      ">epoch=96, lrate=0.100, error=94.550\n",
      ">epoch=97, lrate=0.100, error=94.528\n",
      ">epoch=98, lrate=0.100, error=94.507\n",
      ">epoch=99, lrate=0.100, error=94.486\n",
      ">epoch=0, lrate=0.100, error=142.570\n",
      ">epoch=1, lrate=0.100, error=134.535\n",
      ">epoch=2, lrate=0.100, error=128.794\n",
      ">epoch=3, lrate=0.100, error=124.254\n",
      ">epoch=4, lrate=0.100, error=120.620\n",
      ">epoch=5, lrate=0.100, error=117.662\n",
      ">epoch=6, lrate=0.100, error=115.213\n",
      ">epoch=7, lrate=0.100, error=113.154\n",
      ">epoch=8, lrate=0.100, error=111.400\n",
      ">epoch=9, lrate=0.100, error=109.886\n",
      ">epoch=10, lrate=0.100, error=108.566\n",
      ">epoch=11, lrate=0.100, error=107.405\n",
      ">epoch=12, lrate=0.100, error=106.376\n",
      ">epoch=13, lrate=0.100, error=105.458\n",
      ">epoch=14, lrate=0.100, error=104.633\n",
      ">epoch=15, lrate=0.100, error=103.888\n",
      ">epoch=16, lrate=0.100, error=103.212\n",
      ">epoch=17, lrate=0.100, error=102.596\n",
      ">epoch=18, lrate=0.100, error=102.033\n",
      ">epoch=19, lrate=0.100, error=101.515\n",
      ">epoch=20, lrate=0.100, error=101.039\n",
      ">epoch=21, lrate=0.100, error=100.598\n",
      ">epoch=22, lrate=0.100, error=100.190\n",
      ">epoch=23, lrate=0.100, error=99.811\n",
      ">epoch=24, lrate=0.100, error=99.458\n",
      ">epoch=25, lrate=0.100, error=99.128\n",
      ">epoch=26, lrate=0.100, error=98.820\n",
      ">epoch=27, lrate=0.100, error=98.532\n",
      ">epoch=28, lrate=0.100, error=98.261\n",
      ">epoch=29, lrate=0.100, error=98.006\n",
      ">epoch=30, lrate=0.100, error=97.767\n",
      ">epoch=31, lrate=0.100, error=97.541\n",
      ">epoch=32, lrate=0.100, error=97.328\n",
      ">epoch=33, lrate=0.100, error=97.126\n",
      ">epoch=34, lrate=0.100, error=96.936\n",
      ">epoch=35, lrate=0.100, error=96.755\n",
      ">epoch=36, lrate=0.100, error=96.584\n",
      ">epoch=37, lrate=0.100, error=96.422\n",
      ">epoch=38, lrate=0.100, error=96.267\n",
      ">epoch=39, lrate=0.100, error=96.120\n",
      ">epoch=40, lrate=0.100, error=95.980\n",
      ">epoch=41, lrate=0.100, error=95.847\n",
      ">epoch=42, lrate=0.100, error=95.720\n",
      ">epoch=43, lrate=0.100, error=95.599\n",
      ">epoch=44, lrate=0.100, error=95.484\n",
      ">epoch=45, lrate=0.100, error=95.373\n",
      ">epoch=46, lrate=0.100, error=95.267\n",
      ">epoch=47, lrate=0.100, error=95.166\n",
      ">epoch=48, lrate=0.100, error=95.070\n",
      ">epoch=49, lrate=0.100, error=94.977\n",
      ">epoch=50, lrate=0.100, error=94.888\n",
      ">epoch=51, lrate=0.100, error=94.803\n",
      ">epoch=52, lrate=0.100, error=94.722\n",
      ">epoch=53, lrate=0.100, error=94.643\n",
      ">epoch=54, lrate=0.100, error=94.568\n",
      ">epoch=55, lrate=0.100, error=94.496\n",
      ">epoch=56, lrate=0.100, error=94.426\n",
      ">epoch=57, lrate=0.100, error=94.360\n",
      ">epoch=58, lrate=0.100, error=94.295\n",
      ">epoch=59, lrate=0.100, error=94.233\n",
      ">epoch=60, lrate=0.100, error=94.174\n",
      ">epoch=61, lrate=0.100, error=94.117\n",
      ">epoch=62, lrate=0.100, error=94.061\n",
      ">epoch=63, lrate=0.100, error=94.008\n",
      ">epoch=64, lrate=0.100, error=93.957\n",
      ">epoch=65, lrate=0.100, error=93.907\n",
      ">epoch=66, lrate=0.100, error=93.859\n",
      ">epoch=67, lrate=0.100, error=93.813\n",
      ">epoch=68, lrate=0.100, error=93.769\n",
      ">epoch=69, lrate=0.100, error=93.726\n",
      ">epoch=70, lrate=0.100, error=93.684\n",
      ">epoch=71, lrate=0.100, error=93.644\n",
      ">epoch=72, lrate=0.100, error=93.605\n",
      ">epoch=73, lrate=0.100, error=93.568\n",
      ">epoch=74, lrate=0.100, error=93.531\n",
      ">epoch=75, lrate=0.100, error=93.496\n",
      ">epoch=76, lrate=0.100, error=93.462\n",
      ">epoch=77, lrate=0.100, error=93.429\n",
      ">epoch=78, lrate=0.100, error=93.398\n",
      ">epoch=79, lrate=0.100, error=93.367\n",
      ">epoch=80, lrate=0.100, error=93.337\n",
      ">epoch=81, lrate=0.100, error=93.308\n",
      ">epoch=82, lrate=0.100, error=93.280\n",
      ">epoch=83, lrate=0.100, error=93.253\n",
      ">epoch=84, lrate=0.100, error=93.226\n",
      ">epoch=85, lrate=0.100, error=93.201\n",
      ">epoch=86, lrate=0.100, error=93.176\n",
      ">epoch=87, lrate=0.100, error=93.152\n",
      ">epoch=88, lrate=0.100, error=93.128\n",
      ">epoch=89, lrate=0.100, error=93.106\n",
      ">epoch=90, lrate=0.100, error=93.084\n",
      ">epoch=91, lrate=0.100, error=93.062\n",
      ">epoch=92, lrate=0.100, error=93.042\n",
      ">epoch=93, lrate=0.100, error=93.022\n",
      ">epoch=94, lrate=0.100, error=93.002\n",
      ">epoch=95, lrate=0.100, error=92.983\n",
      ">epoch=96, lrate=0.100, error=92.964\n",
      ">epoch=97, lrate=0.100, error=92.946\n",
      ">epoch=98, lrate=0.100, error=92.929\n",
      ">epoch=99, lrate=0.100, error=92.912\n",
      "Scores: [73.8562091503268, 78.43137254901961, 81.69934640522875, 75.81699346405229, 75.81699346405229]\n",
      "Mean Accuracy: 77.124%\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "import math\n",
    "\n",
    "def load_csv(filename):\n",
    "    dataset = []\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "def str_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "        \n",
    "def find_minmax(dataset):\n",
    "    minmax = []\n",
    "    for i in range(len(dataset[0])):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        value_min = min(col_values)\n",
    "        value_max = max(col_values)\n",
    "        minmax.append([value_min, value_max])\n",
    "    return minmax\n",
    "\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "            \n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = []\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = []\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = []\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores\n",
    "\n",
    "def predict(row, coefficients):\n",
    "    y = coefficients[0]\n",
    "    for i in range(len(row)-1):\n",
    "        y += coefficients[i+1] * row[i]\n",
    "    return 1.0 / (1.0 + math.exp(-y))\n",
    "\n",
    "def coefficients_sgd(train, l_rate, n_epoch):\n",
    "    coef = [0.0 for i in range(len(train[0]))]\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            y = predict(row, coef)\n",
    "            error = row[-1] - y\n",
    "            sum_error += error ** 2\n",
    "            coef[0] = coef[0] + l_rate * error * y * (1.0 - y)\n",
    "            for i in range(len(row)-1):\n",
    "                coef[i+1] = coef[i+1] + l_rate * error * y * (1.0 - y) * row[i]\n",
    "        print (('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error)))\n",
    "    return coef\n",
    "\n",
    "def logistic_regression(train, test, l_rate, n_epoch):\n",
    "    predictions = list()\n",
    "    coef = coefficients_sgd(train, l_rate, n_epoch)\n",
    "    for row in test:\n",
    "        y = predict(row, coef)\n",
    "        y = round(y)\n",
    "        predictions.append(y)\n",
    "    return(predictions)\n",
    "\n",
    "seed(1)\n",
    "filename = 'E:/Kaggle/pima-indians-diabetes.data.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])):\n",
    "    str_to_float(dataset, i)\n",
    "\n",
    "minmax = find_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)\n",
    "\n",
    "n_folds = 5\n",
    "l_rate = 0.1\n",
    "n_epoch = 100\n",
    "scores = evaluate_algorithm(dataset, logistic_regression, n_folds, l_rate, n_epoch)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
